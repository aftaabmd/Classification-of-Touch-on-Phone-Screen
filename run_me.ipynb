{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all the utility files,code written in python 2.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import scipy.io.wavfile\n",
    "\n",
    "\n",
    "class Instance(object):\n",
    "    \"\"\"\n",
    "        Instance class represents set of raw data collected per data instance\n",
    "    \"\"\"\n",
    "    def __init__(self, dir):\n",
    "        self.audio = self._load_audio(dir)\n",
    "        self.touch = self._load_touch_data(dir)\n",
    "        self.info = self._load_instance_info(dir)\n",
    "\n",
    "    def _load_audio(self, dir):\n",
    "        \"\"\" load audio data\n",
    "            param dir: a path to an instance directory\n",
    "            return: audio data\n",
    "        \"\"\"\n",
    "        rate, wav = scipy.io.wavfile.read(os.path.join(dir, \"audio.wav\"))\n",
    "        return wav\n",
    "        \n",
    "    def _load_touch_data(self, dir):\n",
    "        \"\"\" load touch data\n",
    "            param dir: a path to an instance directory\n",
    "            return : a dictionary contains touch data\n",
    "        \"\"\"\n",
    "        with open(os.path.join(dir, \"touch.csv\"), \"rU\") as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            for touch in reader:\n",
    "                for key in  touch.keys():\n",
    "                    touch[key] = float(touch[key])\n",
    "                break\n",
    "        return touch\n",
    "    \n",
    "    def _load_instance_info(self, dir):\n",
    "        \"\"\" load instance info from a directory path\n",
    "            param dir: a path to an instance directory\n",
    "            return: a dictionary contains basic instance information\n",
    "        \"\"\"\n",
    "        info = {}\n",
    "        user_dirnames = os.path.basename(os.path.dirname(dir)).split(\"-\")\n",
    "        info[\"surface\"] = user_dirnames[0]\n",
    "        info[\"user\"] = user_dirnames[1]\n",
    "        instance_dirnames = os.path.basename(dir).split(\"-\")\n",
    "        info[\"timestamp\"] = instance_dirnames[0]\n",
    "        # set None to classlabel if it's test data\n",
    "        info[\"classlabel\"] = instance_dirnames[1] if len(instance_dirnames) == 2 else None\n",
    "        return info\n",
    "def load_instances(dir):\n",
    "    #print dir\n",
    "    \"\"\" function for loading raw data instances\n",
    "        param dir: a path to a data directory (i.e. task_data/train or task_data/test)\n",
    "        return: a list of data instance objects\n",
    "    \"\"\"\n",
    "    instances = []\n",
    "    #print instances\n",
    "    for root, dirs, files in os.walk(os.path.join(dir)):\n",
    "        #print root,dirs,files\n",
    "        for filename in files:\n",
    "            if filename == \"audio.wav\":\n",
    "                instances.append(Instance(root))\n",
    "    return instances\n",
    "\n",
    "def load_labels(instances):\n",
    "    \"\"\" load class labels\n",
    "        param instances: a list of data instance objects\n",
    "        return: class labels mapped to a number (0=pad, 1=knuckle)\n",
    "    \"\"\"\n",
    "    y = np.array([{\"pad\": 0, \"knuckle\": 1}[instance.info[\"classlabel\"]] for instance in instances], dtype=int)\n",
    "    return y\n",
    "\n",
    "\n",
    "def load_timestamps(instances):\n",
    "    \"\"\" load timestamps\n",
    "        param instances: a list of data instance objects\n",
    "    \"\"\"\n",
    "    timestamps = [instance.info[\"timestamp\"] for instance in instances]\n",
    "    return timestamps\n",
    "\n",
    "\n",
    "def convert_to_classlabels(y):\n",
    "    \"\"\" convert to classlabels\n",
    "        param y: mapped class labels\n",
    "        return: class labels\n",
    "    \"\"\"\n",
    "    classlabels = [[\"pad\", \"knuckle\"][y[i]] for i in range(len(y))]\n",
    "    return classlabels\n",
    "\n",
    "\n",
    "def write_results(timestamps, classlabels, output):\n",
    "    \"\"\" write classification results to an output file\n",
    "        param timestamps: a list of timestamps\n",
    "        param classlabels: a list of predicted class labels\n",
    "        return : None\n",
    "    \"\"\"\n",
    "    if len(timestamps) != len(classlabels):\n",
    "        raise Exception(\"The number of timestamps and classlabels doesn't match.\")\n",
    "    with open(output, \"wb\") as f:\n",
    "        f.write(\"timestamp,label\\n\")\n",
    "        for timestamp, classlabel in zip(timestamps, classlabels):\n",
    "            f.write(timestamp + \",\" + classlabel + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# step 1 loading all the data content using the utility files above\n",
    "train_instances = load_instances('./data/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1464. -1485. -1474. ...,  -898.  -898.  -896.]\n",
      " [-1219. -1197. -1214. ...,  -934.  -925.  -938.]\n",
      " [-1273. -1288. -1270. ...,  -735.  -767.  -772.]\n",
      " ..., \n",
      " [-2014. -2003. -1980. ..., -1847. -1907. -1944.]\n",
      " [-2015. -2008. -1996. ..., -1995. -1996. -1982.]\n",
      " [-2000. -2008. -1997. ..., -2091. -2092. -2068.]] (20659L, 256L)\n",
      "(20659L, 13L) [[  8.9284845    1.27909013  -0.16942932 ...,   0.07501468   0.20557355\n",
      "   -0.08660229]\n",
      " [  5.45871065  -0.25808326   0.25652745 ...,  -0.12637589   0.05453893\n",
      "   -0.0379106 ]\n",
      " [  7.34200833   0.43895332   0.63722168 ...,  -0.12781804  -0.04497108\n",
      "   -0.04989088]\n",
      " ..., \n",
      " [ 11.2525355    2.27716453  -0.85784616 ...,  -0.09037062  -0.05465509\n",
      "   -0.07346418]\n",
      " [ 11.30302956   2.29938476  -1.1319388  ...,  -0.10776011   0.35115705\n",
      "   -0.03699211]\n",
      " [ 10.24428125   2.19161288  -0.7221009  ...,  -0.11672084   0.22781351\n",
      "    0.07169545]]\n"
     ]
    }
   ],
   "source": [
    "# loading the audio files, using scikit talkbox library to extract MFCC from those loaded files, library can \n",
    "#installed using setup.py in scikit talkbox folder attached , using command \"python setup.py install\" if any problem\n",
    "# there is a readme.txt explaining more in detail\n",
    "X = np.array([instance.audio.astype(float) for instance in train_instances])# audio files\n",
    "print X, X.shape\n",
    "from scikits.talkbox.features import mfcc\n",
    "p=np.zeros(shape=(20659L, 13))\n",
    "for t,y in enumerate(X):\n",
    "    ceps, mspec, spec = mfcc(y)\n",
    "    p[t]=ceps\n",
    "print p.shape ,p # p containg 13 mfcc coefficients for all the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ {'major': 6.0, 'orientation': -1.0, 'pressure': 0.0, 'y': 1647.0, 'x': 176.0, 'minor': 6.0}\n",
      " {'major': 5.0, 'orientation': -1.0, 'pressure': 0.0, 'y': 1666.0, 'x': 152.0, 'minor': 5.0}\n",
      " {'major': 5.0, 'orientation': -1.0, 'pressure': 0.0, 'y': 1703.0, 'x': 410.0, 'minor': 5.0}\n",
      " ...,\n",
      " {'major': 5.0, 'orientation': -1.0, 'pressure': 0.0, 'y': 1784.0, 'x': 707.0, 'minor': 4.0}\n",
      " {'major': 4.0, 'orientation': -1.0, 'pressure': 0.0, 'y': 1754.0, 'x': 906.0, 'minor': 4.0}\n",
      " {'major': 4.0, 'orientation': -1.0, 'pressure': 0.0, 'y': 1778.0, 'x': 952.0, 'minor': 4.0}]\n",
      "(20659L, 6L)\n",
      "(20659L, 15L) [[  8.9284845    1.27909013  -0.16942932 ...,  -0.08660229   6.           6.        ]\n",
      " [  5.45871065  -0.25808326   0.25652745 ...,  -0.0379106    5.           5.        ]\n",
      " [  7.34200833   0.43895332   0.63722168 ...,  -0.04989088   5.           5.        ]\n",
      " ..., \n",
      " [ 11.2525355    2.27716453  -0.85784616 ...,  -0.07346418   5.           4.        ]\n",
      " [ 11.30302956   2.29938476  -1.1319388  ...,  -0.03699211   4.           4.        ]\n",
      " [ 10.24428125   2.19161288  -0.7221009  ...,   0.07169545   4.           4.        ]]\n"
     ]
    }
   ],
   "source": [
    "#loading touch information and extracting out all important features (including major and minor axis of ellipse)\n",
    "X1=np.array([instance.touch for instance in train_instances])\n",
    "print X1\n",
    "dictlist=[]\n",
    "l=np.zeros(shape=(20659L, 6))\n",
    "for i in range(X1.shape[0]):\n",
    "    for key, value in X1[i].iteritems():\n",
    "        temp = value\n",
    "        dictlist.append(temp)\n",
    "    l[i]=dictlist\n",
    "    dictlist=[]\n",
    "print l.shape # l consists of all the 6 features \n",
    "feat=np.concatenate([p, np.atleast_2d(l[:,0]).T, np.atleast_2d(l[:,5]).T],axis=1) # all the features selected from audio to touch\n",
    "#information 15 (13 MFCC and 2 major and minor axis )\n",
    "print feat.shape,feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ..., 0 0 0]\n",
      "(20659L, 16L) [[  8.9284845    1.27909013  -0.16942932 ...,   6.           6.           0.        ]\n",
      " [  5.45871065  -0.25808326   0.25652745 ...,   5.           5.           0.        ]\n",
      " [  7.34200833   0.43895332   0.63722168 ...,   5.           5.           0.        ]\n",
      " ..., \n",
      " [ 11.2525355    2.27716453  -0.85784616 ...,   5.           4.           0.        ]\n",
      " [ 11.30302956   2.29938476  -1.1319388  ...,   4.           4.           0.        ]\n",
      " [ 10.24428125   2.19161288  -0.7221009  ...,   4.           4.           0.        ]]\n",
      "(20659L, 15L) (20659L,) [ 0.  0.  1. ...,  0.  0.  1.] [[  7.86932862e+00   1.22608086e+00   2.44270648e-01 ...,   1.76541707e-01\n",
      "    5.00000000e+00   5.00000000e+00]\n",
      " [  5.48207805e+00  -2.93169084e-01   5.04493140e-01 ...,  -5.11743783e-02\n",
      "    5.00000000e+00   5.00000000e+00]\n",
      " [  1.29950740e+01   2.72297567e+00  -2.04334512e+00 ...,  -2.41050454e-01\n",
      "    4.00000000e+00   4.00000000e+00]\n",
      " ..., \n",
      " [  6.55007260e+00   8.54746678e-01   5.40850014e-03 ...,   8.82936975e-02\n",
      "    5.00000000e+00   4.00000000e+00]\n",
      " [  5.77197264e+00   6.06222597e-01   6.59571801e-01 ...,  -1.05613971e-01\n",
      "    5.00000000e+00   5.00000000e+00]\n",
      " [  1.47065715e+01   2.47950082e-01  -2.47954235e+00 ...,  -1.35967601e-02\n",
      "    4.00000000e+00   4.00000000e+00]] (20659L, 13L)\n"
     ]
    }
   ],
   "source": [
    "# load labels for the training data\n",
    "y_train = load_labels(train_instances)# labels for the respective samples\n",
    "print y_train\n",
    "x_temp=np.concatenate([feat, np.atleast_2d(y_train).T],axis=1)\n",
    "print x_temp.shape,x_temp\n",
    "np.random.shuffle(x_temp) #randomly shufle data before processing for better estimation of predicted results\n",
    "feat=x_temp[:,0:15] ## data with 15 features including major and minor axis\n",
    "feattt=x_temp[:,0:13] # data with 13 features excluding them\n",
    "y_train=x_temp[:,15]\n",
    "print feat.shape,y_train.shape,y_train,feat,feattt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scikit learn library used to import all the models\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import cross_validation\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import cross_validation\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf10 = AdaBoostClassifier(n_estimators=50)\n",
    "log=LogisticRegression(penalty='l1',C=1)\n",
    "decision = DecisionTreeClassifier( min_samples_split=3)\n",
    "svc = svm.SVC(kernel='linear', C=1)\n",
    "svcrbf = svm.SVC(kernel='rbf', C=1)\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "gnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.897816968624 0.897429676638 0.891911158354 0.93184553876 0.885086411317 0.922164399086 0.900479105988\n"
     ]
    }
   ],
   "source": [
    "# differnt models tried with default parameters with feature engineered dataset\n",
    "scores1234=cross_validation.cross_val_score(svc, feattt, y_train, cv=5)\n",
    "scores1234q=cross_validation.cross_val_score(log, feattt, y_train, cv=5)\n",
    "scores1234r=cross_validation.cross_val_score(decision, feattt, y_train, cv=5)\n",
    "scores1234s=cross_validation.cross_val_score(neigh,feattt, y_train, cv=5)\n",
    "scores1234t=cross_validation.cross_val_score(gnb,feattt, y_train, cv=5)\n",
    "scores1234u=cross_validation.cross_val_score(svcrbf,feattt, y_train, cv=5)\n",
    "scores1234s1=cross_validation.cross_val_score(clf10,feattt, y_train, cv=5)\n",
    "print scores1234.mean(),scores1234q.mean(),scores1234r.mean(),scores1234s.mean(),scores1234t.mean(),scores1234u.mean(),scores1234s1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# bar plot\n",
    "import matplotlib.pyplot as plt\n",
    "values =[scores1234.mean(),scores1234q.mean(),scores1234r.mean(),scores1234s.mean(),scores1234t.mean(),scores1234u.mean(),scores1234s1.mean()]\n",
    "inds   =np.arange(7)\n",
    "labels = [\"Linear SVM\",\"LOGISTIC REG\",\"Decision Trees\",\"KNN\",\"Naive Bayes\",\"RBFSVM\",\"Adaboost(DT)\"]\n",
    "\n",
    "#Plot a bar chart\n",
    "plt.figure(1, figsize=(6,4))  #6x4 is the aspect ratio for the plot\n",
    "plt.bar(inds, values, align='center') #This plots the data\n",
    "plt.grid(True) #Turn the grid on\n",
    "plt.ylabel(\"Accuracy\") #Y-axis label\n",
    "plt.xlabel(\"Method\") #X-axis label\n",
    "plt.title(\"QEEXO dataset\") #Plot title\n",
    "plt.xlim(-0.5,2.5) #set x axis range\n",
    "plt.ylim(0,1) #Set yaxis range\n",
    "\n",
    "#Set the bar labels\n",
    "plt.gca().set_xticks(inds) #label locations\n",
    "plt.gca().set_xticklabels(labels) #label values\n",
    "\n",
    "#Make sure labels and titles are inside plot area\n",
    "plt.tight_layout()\n",
    "\n",
    "#Save the chart\n",
    "#plt.savefig(\"../Figures/digits1.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.93184553876\n",
      "0.934653036576\n",
      "0.934556278023\n",
      "0.934459355432\n",
      "0.932765319147\n"
     ]
    }
   ],
   "source": [
    "# applying cross validation to find optimal hyper parameter C for schosen model SVM RBF kernel\n",
    "K=[3,5,7,9,11]\n",
    "fhg=[]\n",
    "for i in K:\n",
    "    neight = KNeighborsClassifier(n_neighbors=i)\n",
    "    scores1234u=cross_validation.cross_val_score(neight,feattt, y_train, cv=5)\n",
    "    print scores1234u.mean()\n",
    "    fhg.append(scores1234u.mean())\n",
    "\n",
    "plt.figure(1, figsize=(6,4))  #6x4 is the aspect ratio for the plot\n",
    "plt.plot(K,fhg,'or-', linewidth=3) #Plot the first series in red with circle marker#Plot the first series in blue with square marker\n",
    "\n",
    "#This plots the data\n",
    "plt.grid(True) #Turn the grid on\n",
    "plt.ylabel(\"accuracy\") #Y-axis label\n",
    "plt.xlabel(\"K values\") #X-axis label\n",
    "plt.title(\"K vs accuracy Values\") #Plot title\n",
    "plt.xlim(-0.1,13) #set x axis range\n",
    "plt.ylim(0.7,1) #Set yaxis range\n",
    "\n",
    "#Make sure labels and titles are inside plot area\n",
    "plt.tight_layout()\n",
    "\n",
    "#Save the chart\n",
    "#plt.savefig(\"../Figures/linegraph1.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1627. -1646. -1637. ..., -1530. -1561. -1547.]\n",
      " [-1579. -1564. -1584. ..., -1871. -1873. -1866.]\n",
      " [-1751. -1747. -1729. ..., -2153. -2154. -2141.]\n",
      " ..., \n",
      " [-2047. -2049. -2047. ..., -2111. -2016. -2000.]\n",
      " [-2047. -2051. -2098. ..., -2175. -2143. -2121.]\n",
      " [-2062. -2040. -2048. ..., -2345. -2280. -2264.]] (10528L, 256L)\n",
      "(10528L, 13L) [[  8.35596137e+00   2.43506263e+00   1.28172096e+00 ...,  -1.53605112e-01\n",
      "    8.73525735e-02  -8.81050329e-02]\n",
      " [  1.02174225e+01   3.13441687e+00   1.55497149e+00 ...,  -5.19709272e-01\n",
      "    2.62648674e-01  -3.13623564e-02]\n",
      " [  8.96760568e+00   2.28227244e+00   1.60344381e+00 ...,  -1.26103883e-01\n",
      "   -2.39157673e-01   1.65562771e-01]\n",
      " ..., \n",
      " [  1.65464938e+01   1.91863599e+00  -2.68081348e+00 ...,   2.05709841e-01\n",
      "    8.54158801e-02  -6.76919755e-02]\n",
      " [  1.58946592e+01   1.76845684e+00  -2.04156575e+00 ...,  -1.22442740e-01\n",
      "    1.59359787e-01  -2.97846607e-01]\n",
      " [  7.00045578e+00   1.21046737e+00   1.20473140e+00 ...,  -1.13147275e-02\n",
      "   -7.38034810e-02  -1.04885873e-02]]\n",
      "(10528L, 13L)\n",
      "0.935282424133\n"
     ]
    }
   ],
   "source": [
    "# chosen model with optimal hyper parameter is fitted to the training data and predicted on test data ,values are stored in a \n",
    "#csv file\n",
    "test_instances = load_instances(\"./data/test\")\n",
    "X_test = np.array([instance.audio.astype(float) for instance in test_instances])# audio files\n",
    "print X_test, X_test.shape\n",
    "from scikits.talkbox.features import mfcc\n",
    "p_test=np.zeros(shape=(10528L, 13))\n",
    "for t,y in enumerate(X_test):\n",
    "    ceps, mspec, spec = mfcc(y)\n",
    "    p_test[t]=ceps\n",
    "print p_test.shape ,p_test \n",
    "feat_test=p_test # all the features selected from audio 13 MFCC \n",
    "print feat_test.shape\n",
    "neight = KNeighborsClassifier(n_neighbors=5)\n",
    "scores1234u=cross_validation.cross_val_score(neight,feattt, y_train, cv=5)\n",
    "print scores1234u.mean()\n",
    "neight.fit(feattt,y_train)\n",
    "y_test=neight.predict(feat_test)\n",
    "y_test=y_test.astype(int)\n",
    "timestamps = load_timestamps(test_instances)\n",
    "classlabels = convert_to_classlabels(y_test)\n",
    "write_results(timestamps, classlabels, \"./fingersense-test-labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20659L, 13L) [[ -5.03647090e+00  -7.01778431e+00  -1.61908719e+00 ...,   3.25365885e-01\n",
      "    1.18287542e-01   5.26893813e-02]\n",
      " [ -5.71450571e+00  -7.65847435e+00  -6.29332866e-01 ...,   7.31211407e-03\n",
      "   -6.41196483e-03   2.72746185e-02]\n",
      " [ -7.11176578e+00  -7.62313820e+00   1.50332206e+00 ...,   1.64155032e-02\n",
      "    1.08035092e-01  -1.61774716e-01]\n",
      " ..., \n",
      " [ -2.81847595e+00  -2.58776997e+00   3.51470334e-02 ...,  -2.02372380e-02\n",
      "    1.96083877e-01   1.66761052e-01]\n",
      " [ -2.89219574e+00  -2.74333269e+00   1.66031734e-01 ...,   1.35663867e-02\n",
      "    1.27943875e-02  -3.29139905e-02]\n",
      " [ -3.48581124e+00  -3.85048823e+00  -2.14277174e-01 ...,  -6.05145976e-03\n",
      "    9.07353629e-02  -6.65807550e-02]]\n",
      "(20659L, 26L)\n",
      "0.919066613894\n"
     ]
    }
   ],
   "source": [
    "#Other different features tried to use using python_speech_features library , installed exactly same as talkbox using command  \n",
    "# python setup.py install, turned out these featurs didnt make much changes, so they were not considered later\n",
    "from python_speech_features import delta\n",
    "p2=np.zeros(shape=(20659,13))\n",
    "for t,y in enumerate(feattt):\n",
    "    delt=delta(y,1)\n",
    "    p2[t]=delt\n",
    "print p2.shape,p2\n",
    "feat3=np.concatenate([feattt,p2],axis=1)\n",
    "print feat3.shape\n",
    "scores1234s1=cross_validation.cross_val_score(svcrbf,feat3, y_train, cv=5)\n",
    "print scores1234s1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20415L, 13L) [[  1.31489550e+01   3.07601325e+00  -8.86613587e-01 ...,   1.54296890e-01\n",
      "    2.85493213e-01   3.90871975e-01]\n",
      " [  1.30391795e+01   1.61016807e+00  -2.27776922e+00 ...,   3.01272852e-02\n",
      "   -3.72458813e-02   1.73033556e-02]\n",
      " [  1.28017153e+01  -1.42181626e+00  -2.44456110e+00 ...,  -3.44790274e-01\n",
      "    1.94829341e-01  -1.28720090e-01]\n",
      " ..., \n",
      " [  6.55621939e+00   9.19267501e-01   1.38067946e+00 ...,  -1.81457387e-01\n",
      "   -1.22811737e-01   2.10710367e-01]\n",
      " [  5.55614122e+00  -2.28250274e-01   6.94758372e-02 ...,   2.39675803e-03\n",
      "    9.38135140e-02   2.79855330e-02]\n",
      " [  8.50292876e+00   1.53130628e+00   8.01952297e-01 ...,  -4.77362685e-02\n",
      "    2.66895967e-01   1.33734457e-01]] (20415L,) [ 1.  1.  1. ...,  0.  0.  0.]\n",
      "(244L,)\n",
      "[ 0.  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  1.  0.\n",
      "  1.  0.  0.  0.  1.  0.  0.  1.  0.  1.  0.  1.  1.  0.  1.  0.  0.  1.\n",
      "  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  0.  1.  1.\n",
      "  0.  1.  1.  0.  0.  0.  1.  1.  1.  0.  1.  0.  0.  1.  0.  0.  1.  1.\n",
      "  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.  1.  0.  1.  0.  1.  0.  1.  1.\n",
      "  1.  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.\n",
      "  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  0.  1.  1.  1.  1.\n",
      "  0.  0.  1.  1.  1.  1.  0.  1.  0.  1.  0.  1.  0.  1.  1.  1.  0.  0.\n",
      "  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.  1.\n",
      "  1.  1.  1.  1.  1.  0.  1.  1.  0.  0.  1.  0.  0.  0.  1.  1.  0.  0.\n",
      "  1.  1.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  1.\n",
      "  1.  0.  1.  1.  1.  1.  1.  0.  0.  0.  1.  0.  0.  1.  1.  1.  0.  0.\n",
      "  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  1.  1.  1.\n",
      "  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.] [ 0.  0.  1.  0.  0.  1.  0.  0.  1.  0.  0.  0.  1.  0.  0.  1.  1.  0.\n",
      "  1.  0.  0.  0.  1.  0.  1.  1.  0.  1.  0.  1.  1.  0.  1.  0.  0.  1.\n",
      "  0.  0.  1.  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  1.  1.  0.  1.  1.\n",
      "  0.  1.  1.  0.  0.  0.  1.  1.  0.  0.  1.  0.  0.  1.  0.  0.  1.  1.\n",
      "  1.  0.  1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.  1.  0.  1.  1.\n",
      "  1.  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0.  0.  1.  0.\n",
      "  0.  0.  1.  0.  0.  0.  1.  1.  0.  1.  1.  1.  0.  0.  1.  1.  1.  1.\n",
      "  0.  0.  1.  1.  1.  1.  0.  1.  0.  1.  0.  1.  0.  1.  1.  1.  0.  0.\n",
      "  0.  0.  0.  1.  0.  1.  1.  0.  0.  1.  1.  1.  1.  1.  1.  0.  1.  1.\n",
      "  1.  1.  1.  1.  1.  0.  1.  1.  0.  0.  1.  0.  0.  0.  1.  0.  0.  0.\n",
      "  1.  1.  0.  1.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  1.  1.\n",
      "  1.  0.  1.  0.  1.  1.  1.  0.  0.  1.  1.  0.  0.  1.  1.  1.  0.  0.\n",
      "  0.  1.  0.  0.  0.  0.  0.  1.  1.  1.  0.  0.  1.  0.  1.  1.  1.  1.\n",
      "  0.  0.  1.  0.  0.  1.  1.  0.  1.  0.] [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      " False  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True False  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True False  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True False  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True False  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True False  True  True\n",
      "  True  True  True  True  True  True False  True  True  True  True  True\n",
      "  True  True  True  True False  True  True  True  True False  True  True\n",
      "  True  True  True False  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True False  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "# out of training data some data was kept aside to test model accuracy as we know the labels of them, turns out it wrongly labels 8out \n",
    "# 244\n",
    "testtt=feattt[18256:18500,:]\n",
    "y_Testt=y_train[18256:18500]\n",
    "neight = KNeighborsClassifier(n_neighbors=5)\n",
    "ghj=np.concatenate([feattt[0:18256,:], feattt[18500:,:]])\n",
    "lkj=np.concatenate([y_train[0:18256], y_train[18500::]])\n",
    "print ghj.shape,ghj, lkj.shape,lkj\n",
    "neight.fit(ghj,lkj)\n",
    "ypredd=neight.predict(testtt)\n",
    "print ypredd.shape\n",
    "print ypredd,y_Testt,ypredd==y_Testt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20659L, 13L) (20659L, 560L)\n",
      "0.934556278023\n"
     ]
    }
   ],
   "source": [
    "#try to increase the features size using basis expansion technique turns out it didnt increase accuracy as well.\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "featpoly= PolynomialFeatures(3)\n",
    "featpol=featpoly.fit_transform(feattt)\n",
    "print feattt.shape,featpol.shape\n",
    "neight = KNeighborsClassifier(n_neighbors=7)\n",
    "scores1234u=cross_validation.cross_val_score(neight,feattt, y_train, cv=5)\n",
    "print scores1234u.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
